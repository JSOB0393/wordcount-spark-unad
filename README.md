üß† Proyecto Acad√©mico UNAD ‚Äì Big Data Integration
WordCount con PySpark y Apache Spark sobre Hadoop

Este proyecto implementa un contador de palabras (WordCount) utilizando PySpark sobre un entorno Hadoop en Ubuntu.
Forma parte de la gu√≠a pr√°ctica de la asignatura Big Data Integration del programa de Ciencia de Datos y Anal√≠tica en la UNAD (Universidad Nacional Abierta y a Distancia).

üìò Descripci√≥n General

El objetivo del proyecto es procesar un archivo de texto y analizar la frecuencia de aparici√≥n de palabras clave utilizando el modelo de programaci√≥n distribuida de Apache Spark.
Se trabaja en un entorno local, configurado sobre una m√°quina virtual con Ubuntu y Hadoop, para simular un ecosistema de Big Data.

‚öôÔ∏è Requisitos del Entorno

Ubuntu 22.04 (en VirtualBox)

Hadoop 3.3.6

Apache Spark 3.5.0

Python 3.12

PySpark

Git y GitHub

üìÑ Archivos del Proyecto
Archivo	Descripci√≥n
Aplicacion.txt	Texto base para an√°lisis de palabras.
wordcount_pyspark.py	Script principal en PySpark.
resultado_wordcount.html	Salida del conteo en formato HTML.
Hadoop Install JuanSebastianOspinaBarreto.mp4	Video demostrativo de la instalaci√≥n del entorno.

üé• Video de la Instalaci√≥n y Ejecuci√≥n

üßæ Licencia

Este proyecto se publica bajo la licencia MIT.
Desarrollado por Juan Sebastian Ospina Barreto (JSOB0393) para fines acad√©micos.
